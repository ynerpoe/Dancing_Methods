Instructions
1. First, capture video in MP4 format, which will be used in the subsequent analysis.
2. Next, use the Openpose code that, based on the video captured in the previous step, generates an output file in JSON format, 
containing coordinates for 25 points, including head, chest, hands, feet, knees, hips, shoulders, etc. Each point is associated with three parameters:
two XY coordinates and a confidence coordinate (C) indicating the confidence level of obtaining the XY coordinates. 
Thus, each point of interest is P(x, y, c). General instructions for using Openpose can be found at the following link:
https://github.com/CMU-Perceptual-Computing-Lab/openpose
3. Subsequently, convert the Openpose JSON files to a CSV file using the R code available at https://osf.io/ybezd
4. Once the CSV file with the 25 available points is obtained, select the point of interest for analysis. 
This point represents the body part whose movement is of interest for analysis. 
From this, generate a CSV file with the data in columns arranged in the same order as the selected point.
5. Finally, use the Matlab code (Symchrony_dyad_analysis_new2.m) that combines data preprocessing, visualization, 
and advanced signal processing techniques (cross-correlation, wavelet coherence, and phase analysis) to analyze 
and characterize the relationships between movements of different body parts over time. 
The results, including visualizations and calculated metrics, are saved for further examination. 
This code is available at: https://github.com/ynerpoe/Dancing_Methods/blob/main/Synchrony_dyad_analysis_new2.m 

