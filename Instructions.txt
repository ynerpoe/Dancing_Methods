To perform the complete analysis, you must follow the following instructions:

1. First, capture the video in MP4 format, which will be used in the subsequent analysis (see the "Videos_examples" folder.
The Video_example_dyad.mp4 is just an example, the actual videos involve mothers and their preschool children)

2. Next, use the Openpose code that, based on the video captured in the previous step generates an output file in JSON format, 
containing coordinates for 25 points, including head, chest, hands, feet, knees, hips, shoulders, etc. Each point is associated with three parameters:
two XY coordinates and a confidence coordinate (C) indicating the confidence level of obtaining the XY coordinates. 
Thus, each point of interest is P(x, y, c) (see JSON_files.zip in the "Results" folder).
General instructions for using Openpose can be found at the following link: https://github.com/CMU-Perceptual-Computing-Lab/openpose

3. Subsequently, convert the Openpose JSON files to a CSV file using the R code available at https://github.com/ynerpoe/Dancing_Methods/tree/main/R%20scripts

4. Once the CSV file with the 25 available points is obtained, use the tenser_test_0_2 Matlab code

